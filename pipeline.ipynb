{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Politician Accounts / Party Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = pd.json_normalize(json.load(open(\"followed-accounts.json\")))\n",
    "\n",
    "accs.to_csv(\"accounts.csv\", index=False)\n",
    "\n",
    "# alternatively: accs = pd.read_csv(\"accounts.csv\", converters = {x: pd.eval for x in range(5)})\n",
    "politicians = np.concatenate(accs.values[0])\n",
    "\n",
    "def extract_party(mention_str):\n",
    "    return [acc_dict[mention[\"screen_name\"]] if mention[\"screen_name\"] in acc_dict.keys() else \"Neutral\" for mention in eval(mention_str)]\n",
    "\n",
    "acc_dict = {}\n",
    "\n",
    "for party in accs:\n",
    "    for member in accs[party].values[0]:\n",
    "        acc_dict[member] = party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_first_n_chunks(n):\n",
    "    return pd.concat([pd.json_normalize(json.load(open(\"chunks/\" + chunk))) for chunk in tqdm(os.listdir(\"chunks\")[0:n])])\n",
    "\n",
    "raw = load_first_n_chunks(10)\n",
    "# drop tweets where content and user identical\n",
    "raw = raw.drop_duplicates(subset=[\"text\", \"user.id\"])\n",
    "# alternatively: raw = pd.read_csv(\"raw_10.csv\")\n",
    "raw.to_csv(\"raw_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Condensed Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "condensed = raw[[\"id\", \"created_at\", \"user.id\", \"user.screen_name\", \"user.followers_count\",\n",
    "     \"text\", \"in_reply_to_status_id\",\n",
    "     \"entities.hashtags\", \"entities.user_mentions\",\n",
    "     \"quoted_status_id\", \"retweeted_status.id\", \"retweet_count\", \"favorite_count\"]]\n",
    "\n",
    "condensed = condensed.assign(is_politician=raw[\"user.screen_name\"].isin(politicians))\n",
    "condensed.loc[condensed['is_politician'] == True, 'author_party'] = 1\n",
    "condensed[\"author_party\"] = condensed[\"user.screen_name\"].apply(lambda x: acc_dict[x] if x in acc_dict.keys() else \"None\")\n",
    "condensed.to_csv(\"condensed_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\anaconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from germansentiment import SentimentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed = pd.read_csv(\"condensed_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crashes because of memory error\n",
    "#sentiment = pd.DataFrame({\"text\": condensed.text.drop_duplicates().head(100), \"sentiment\": model.predict_sentiment(condensed.text.drop_duplicates()).head(100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [04:10<00:00, 16.71s/it]\n"
     ]
    }
   ],
   "source": [
    "text = condensed.text.drop_duplicates()\n",
    "num_chunks = 15\n",
    "chunk_size = len(text)//num_chunks\n",
    "textcontent = []\n",
    "sentiment = []\n",
    "for i in tqdm(range(num_chunks)):\n",
    "    textcontent += list(text.iloc[i*chunk_size:(i+1)*chunk_size])\n",
    "    sentiment += model.predict_sentiment(text.iloc[i*chunk_size:(i+1)*chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = pd.DataFrame({\"text\": textcontent, \"sentiment\": sentiment})\n",
    "df_sent = condensed.merge(df_sent, on=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent.to_csv(\"sentiment_10.csv\", inde)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
